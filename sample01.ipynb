{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e516a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "sample01-project\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"sample01-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683ecfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 이를 가공하여 원하는 결과를 출력하는 과정을 말합니다. 이때, 모델은 입력 데이터와 출력 결과 사이의 패턴을 학습하여 이후 새로운 입력 데이터에 대해 정확한 결과를 예측할 수 있도록 학습됩니다.\n",
      "\n",
      "모델이 학습하는 과정은 크게 입력층, 은닉층, 출력층으로 구성됩니다. 입력층에서는 외부에서 입력된 데이터가 모델에 들어가고, 은닉층에서는 입력된 데이터를 가공하여 중요한 패턴을 추출합니다. 마지막으로 출력층에서는 은닉층에서 추출된 패턴을 바탕으로 원하는 결과를 출력합니다.\n",
      "\n",
      "모델은 학습 데이터를 이용하여 입력과 출력 간의 관계를 찾아내는 과정을 거치는데, 이때 손실 함수를 통해 모델의 예측 결과와 실제 결과 간의 차이를 계산하고 이를 최소화하는 방향으로 모델을 학습시킵니다. 이러한 과정을 여러 번 반복하여 모델이 입력과 출력 간의 관계를 더욱 정확하게 학습할 수 있도록 합니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "# template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# # from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "# prompt_template = PromptTemplate.from_template(template)\n",
    "# prompt_template\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "# chain.invoke(input)\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8b657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 회화:\n",
      "- Hello, I'd like to order a pizza for delivery.\n",
      "- Sure, what size are you looking for?\n",
      "- I'll have a large pizza, half pepperoni and half cheese.\n",
      "- Any sides or drinks?\n",
      "- Yes, a side of garlic bread and two cans of Coke, please.\n",
      "- Great, can I have your address?\n",
      "- It’s 452 Park Avenue, Apartment 21B.\n",
      "- The total comes to $24.50. It should take about 30-45 minutes for delivery.\n",
      "- Perfect, thank you!\n",
      "\n",
      "한글 해석:\n",
      "- 안녕하세요, 배달할 피자를 주문하고 싶습니다.\n",
      "- 네, 어떤 사이즈를 원하시나요?\n",
      "- 대형 피자 하나로, 한쪽은 페퍼로니, 다른 한쪽은 치즈로 해주세요.\n",
      "- 사이드 메뉴나 음료는 필요하신가요?\n",
      "- 네, 마늘 빵 하나와 코카콜라 두 캔 주세요.\n",
      "- 좋습니다, 주소를 알려주시겠어요?\n",
      "- 452 파크 애비뉴, 아파트 21B입니다.\n",
      "- 총 금액은 $24.50이고, 배달은 약 30-45분 정도 걸릴 예정입니다.\n",
      "- 완벽해요, 감사합니다!"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "# answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# # 스트리밍 출력\n",
    "# stream_response(answer)\n",
    "\n",
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
